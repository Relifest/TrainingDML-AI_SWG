== IO Module

=== Reading - Dataset Encoding Input

==== Local File Input (Reading TrainingDML-AI Encoding from Local Files)

The functionality is located in tdml_readers.py within the IO module, primarily used for reading TrainingDML-AI encoded data from local files.

(1) Function: read_from_json(file_path: str)

====
a) Description:

* Reads a TDML JSON file from the specified path and returns a _TrainingDataset_ object.

b) Parameter:

* file_path(string): The path to the JSON file.
====

(2) Function: parse_json(json_dict)

====
a) Description:

Parses a JSON dictionary and returns the corresponding _TrainingDataset_ object based on its type.

b) Parameter:

* json_dict (dictionary): The dictionary representation of the JSON data.
====

*Example:*

Suppose we have a local file named data.json with the following content:

----
{
    "type": "TrainingDataset",
    "name": "example_dataset",
    "description": "This is an example training dataset.",
    "data": [
        {
            "id": "1",
            "label": "cat",
            "image": "cat1.jpg"
        },
        {
            "id": "2",
            "label": "dog",
            "image": "dog1.jpg"
        }
    ]
}
----

The user runs the following code:

----
from tdml_reader import read_from_json
file_path = "data.json"
training_dataset = read_from_json(file_path)
print(training_dataset)
----

After executing the above code, data.json will be read and its content will be parsed into a _TrainingDataset_ object. The detailed information of this object will then be printed.

==== S3 Path Reading (Reading TrainingDML-AI Encoding from S3 Object Files)

The functionality is located in S3_reader.py within the IO module, primarily used to read TrainingDML-AI encoded data from S3 object storage.

(1) Function: parse_s3_path(s3_path)

====
a) Description:

* Parses an S3 path to extract the bucket name and object key.

b) Parameter:

* s3_path(string): The S3 path.
====

(2) Class _LibraryNotInstalledError_

====
a) Description:

* A custom exception class that is raised when a required library is not installed.
====

(3) Class _S3Client_

====
a) Description:

* The class is used for interacting with the S3 service.

b) Constructor Parameters

* resource(string): The type of resource (e.g., 's3').

* server(string): The S3 server address.

* access_key(string): The access key.

* secret_key(string): The secret key.

c) Methods

* list_buckets()

    Functionality: Lists all buckets.
    Return: A list of bucket names.

* list_objects(bucket_name, prefix)

    Functionality: Lists all objects in a specified bucket.
    Parameters:
        bucket_name (string): The name of the bucket.
        prefix (string): The object prefix.
    Return: A list of object keys.

* get_object(bucket, key)

    Functionality: Retrieves the content of a specified object.
    Parameters:
        bucket (string): The name of the bucket.
        key (string): The object key.
    Return: A BytesIO stream of the object's content.

* download_file(bucket_name, object_key, file_path)

    Functionality: Downloads a specified object to a local file.
    Parameters:
        bucket_name (string): The name of the bucket.
        object_key (string): The object key.
        file_path (string): The local file path.
        Exception Handling: If an exception occurs during download, an error message will be printed.
====

*Example:*

Suppose we have an S3 path such as s3://my-bucket/my-folder/my-object.json which stores TrainingDML-AI encoded data. The user can run the following code:

----
from S3_reader import S3Client, parse_s3_path
resource = 's3'
server = 'https://s3.amazonaws.com'
access_key = 'your_access_key'
secret_key = 'your_secret_key'
s3_path = 's3://my-bucket/my-folder/my-object.json'
s3_client = S3Client(resource, server, access_key, secret_key)
bucket_name, object_key = parse_s3_path(s3_path)
s3_object = s3_client.get_object(bucket_name, object_key)
import json
json_dict = json.load(s3_object)
# Print the JSON data
print(json_dict)
----

In the above code, the user needs to provide S3 service configuration details, including the server address, access key, and secret key. Then, an _S3Client_ instance is created. The S3 path is parsed to obtain the bucket name and object key. The _S3Client_ instance is then used to retrieve the object content from S3, which is parsed as JSON and printed.

=== Organizing and Generating TrainingDML-AI Code Based on Local Dataset

Organizing and generating TrainingDML-AI code based on the local dataset requires two ways to obtain information: manual input and function calls. The specific steps are as follows:

==== Organizing Data and Metadata Information in the Dataset to Generate a _TrainingData_

Introduce classes such as _TrainingData_ and _SceneLabel_, obtain information including data directory and file location, and organize them into _TrainingData_'s parameters.


*Example:*

----
import os
from pytdml.type import EOTrainingData, SceneLabel
td_list = []
image_path = r"TrainingDatasets\WHU-RS19\image"
for root, dirs, files in os.walk(image_path):
    for file in files:
        tdml = EOTrainingData(
            id=file.split(".")[0],
            labels=[SceneLabel(label_class=os.path.relpath(root, image_path))],
            data_url=os.path.join(root, file),
            date_time="2010"
        )
        td_list.append(tdml)
----

==== Organizing the _TrainingData_ and Other Metadata Information into a _TrainingDataset_

Introduce classes such as _TrainingDataset_ and _Task_, input metadata information manually, and combine the _TrainingData_ from the previous step. Organize them into a _TrainingDataset_.

*Example:*

----
from pytdml.type import EOTrainingDataset, EOTask

whu_rs19 = EOTrainingDataset(
    id='whu_rs19',
    name='WHU_RS19',
    description="WHU-RS19 has 19 classes of remote sensing images scenes obtained from Google Earth",
    tasks=[EOTask(task_type="Scene Classification", description="Structural high-resolution satellite image indexing")],
    data=td_list,
    version="1.0",
    amount_of_training_data=len(td_list),
    created_time="2010",
    updated_time="2010",
    providers=["Wuhan University"],
    keywords=["Remote Sensing", "Scene Classification"],
    data_sources=["https://earth.google.com/"],
    classes=["Airport", "Beach", "Bridge", "Commercial", "Desert", "Farmland", "footballField", "Forest", "Industrial", "Meadow", "Mountain", "Park", "Parking", "Pond", "Port", "railwayStation", "Residential", "River", "Viaduct"],
    number_of_classes=19,
    bands=["red", "green", "blue"],
    image_size="600x600"
)
----

==== Writing a _TrainingDataset_ as a JSON File and Outputting it Locally

The functionality is located in tdml_writers.py within the IO module, primarily used to write a _TrainingDataset_ as a JSON file and output it locally.

(1) Function: write_to_json(td: TrainingDataset, file_path: str, indent: Union[None, int, str] = 4)

====
a) Description:

* Writes a _TrainingDataset_ to a JSON file.

b) Parameter:

* td: Basic training dataset type

* file_path: The path where the file will be stored.

* indent: If “indent” is a non-negative integer, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0 will only insert newlines. “None” is the most compact representation.
====

*Example:*
----
from pytdml.io import write_to_json
write_to_json(td, file_path)
----

=== Transform YAML to TDML

YAML (Yet Another Markup Language) is a commonly used data serialization format aimed at providing a data serialization standard that is easy for humans to read and write. The YAML configuration file schema is described in the YAML configuration file schema section. The functionality is located in yaml_to_tdml.py.

(1) Function: yaml_to_eo_tdml(yaml_path)

====
a) Description:

* Converts a YAML file to an _EOTrainingDataset_.

b) Parameter:

* yaml_path: The path where the YAML file is stored.

c) Return:

* _EOTrainingDataset_: Extended training dataset type for EO training dataset.
====

*Example:*

----
from pytdml.yaml_to_tdml import yaml_to_eo_tdml
training_datasets = yaml_to_eo_tdml(yaml_path)
----

=== Format Conversion

The functionality is located in convert_utils.py, primarily used to convert different formats to TrainingDML-AI encoding.

(1) Function: convert_coco_to_tdml(coco_dataset_path, output_json_path)

====
a) Description:

* Converts COCO format to TrainingDML-AI encoding. Reads data from a COCO-formatted JSON file and saves it after converting it to a new JSON document.

b) Parameter:

* coco_dataset_path: The path to the JSON file in COCO format.

* output_json_path: The path to output the JSON file after conversion.
====

*Example:*

----
from pytdml.convert_utils import convert_coco_to_tdml
convert_coco_to_tdml(coco_dataset_path, output_json_path)
----

(2) Function: convert_stac_to_tdml(stac_dataset_path, output_json_path)

====
a) Description:

* Converts STAC format to TrainingDML-AI encoding. Reads JSON data in STAC format from a given path.

b) Parameter:

* stac_dataset_path: The path to the JSON file in STAC format.

* output_json_path: The path to output the JSON file after conversion.
====

*Example:*

----
from pytdml.convert_utils import convert_coco_to_tdml
convert_stac_to_tdml(stac_dataset_path, output_json_path)
----